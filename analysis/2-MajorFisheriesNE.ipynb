{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d10a8ea-eeb3-450b-bf1e-0a55e440428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "format: \n",
    "  html:\n",
    "    toc: false\n",
    "    page-layout: full\n",
    "execute:\n",
    "    echo: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ca5ab4-cf25-42a4-bf80-80e8ec3b99d4",
   "metadata": {},
   "source": [
    "# Major Fisheries along the North Atlantic Coast\n",
    "QUESTION 2: Where are the most important fisheries along the north Atlantic Coast and what factors define the most important fishing ports? \n",
    "\n",
    "Select based on: \n",
    "- 2022 data\n",
    "- % of regional fish quantity\n",
    "- % GDP from maritime activities of county\n",
    "- % of employment in fishing\n",
    "- Density of fishing vessel activity\n",
    "\n",
    "Mariya Lupandina and Clarasophia Gust\n",
    "MUSA 550 | Fall 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e996c34-3ddc-42b0-8b94-da8f5e21cce1",
   "metadata": {},
   "source": [
    "#### Download required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "d8471427-06e0-440a-a5ff-c4517b21baeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import zipfile\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import datetime\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2e50c6-4aca-435e-bc33-226728d33b79",
   "metadata": {},
   "source": [
    "#### Specify Region of Interest\n",
    "For this project, we are interested in the fisheres along the north Atlantic Coast from Delaware to Maine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a3961461-6782-49a4-9e78-9631e4f91b4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create list of States of Interest\n",
    "\n",
    "States_short = ['DE', 'PA', 'NJ', 'NY', 'CT', 'RI', 'MA', 'NH', 'ME']\n",
    "States_long = ['DELAWARE', 'PENNSYLVANIA', 'NEW JERSEY', 'NEW YORK', 'CONNECTICUT', 'RHODE ISLAND', 'MASSACHUSETTS', 'NEW HAMPSHIRE', 'MAINE']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0b18f0-99c1-4b9a-b786-6669314a409b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Landings in 2022 (quantity of fish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b0bafd87-bd23-41ca-a2b5-227a4693b752",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reqest landings data from NOAA Fisheries API\n",
    "\n",
    "url = \"https://apps-st.fisheries.noaa.gov/ods/foss/landings/?offset=0&limit=100000\"\n",
    "params = {\"state_name\": States_long, \"year\": \"2022\"}\n",
    "response = requests.get(url, params=params)\n",
    "landingsdata = response.json()\n",
    "\n",
    "# Turn the requested vessel data into a data frame\n",
    "\n",
    "items = landingsdata['items']\n",
    "landings_df = pd.DataFrame(items)\n",
    "len(landings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6daf35f-46c9-45c5-b3ae-5075ca9ce9e2",
   "metadata": {},
   "source": [
    "#### Fishing Vessel Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "6bf104a1-cb6a-43ad-a26d-f4515b8977d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Request vessel data from NOAA Fisheries API \n",
    "###(NOTE TO MARIYA: I'm not sure whether it is pulling all of the pages of data. I tried to write a code which cycled through the data pages but couldn't get it to work.)\n",
    "\n",
    "url = \"https://apps-st.fisheries.noaa.gov/ods/foss/vessel_data/?offset=0&limit=50000\"\n",
    "paramsvessel = {\"hail_state\": States_short}\n",
    "response = requests.get(url, params=paramsvessel)\n",
    "vesseldata = response.json()\n",
    "\n",
    "# Turn the requested vessel data into a data frame\n",
    "\n",
    "items = vesseldata['items']\n",
    "vessels_df = pd.DataFrame(items)\n",
    "len(vessels_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
